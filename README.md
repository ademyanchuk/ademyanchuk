# Hi, I'm Alexey ğŸ‘‹

I'm a Machine Learning researcher currently working at the intersection of ML and medical research. Alongside my professional work, I'm independently deepening my technical skills by building large language models from scratch.

Currently:
- ğŸ¯ Working through Andrej Karpathyâ€™s "Zero to Hero" series
- ğŸ› ï¸ Building and training a from-scratch GPT-2 model (`gpt2-diy`)
- ğŸ§  Focusing on understanding transformers, scaling behaviors, and efficient training dynamics

I'm particularly interested in:
- Large Language Model (LLM) internals
- Model interpretability and robustness
- Scalable and responsible AI development

**Current Projects:**
- [minbpe](https://github.com/ademyanchuk/minbpe) â€” A minimal, from-scratch BPE tokenizer
- [gpt2-diy](https://github.com/ademyanchuk/gpt2-diy) â€” Reproducing GPT-2 from scratch as a learning journey

---

**Building deep foundations, one token at a time.**  
Always happy to connect with fellow researchers, engineers, and builders in the ML/AI space!

ğŸ“« How to reach me: [LinkedIn](https://www.linkedin.com/in/alexey-demyanchuk/)
